<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>Machine Learning, NLP</description>
    <link>
    </link>
    
      
      <item>
        <title>mcQA - Multiple Choice Question Answering</title>
        
          <description>&lt;p&gt;mcQA is a multiple choice question answering python library, using Language Models.&lt;/p&gt;

</description>
        
        <pubDate>Wed, 10 Jul 2019 02:25:36 -0500</pubDate>
        <link>
        /mcQA</link>
        <guid isPermaLink="true">/mcQA</guid>
      </item>
      
    
      
      <item>
        <title>Building Parallel Corpora Using Cross-Lingual BOW</title>
        
          <description>&lt;p&gt;Training machine translation models requires a huge amount of parallel data.
Consequently, there has been many works suggesting different methods to build
bilingual corpora, leading to the construction of reliable training datasets for
machine translation systems.&lt;/p&gt;

</description>
        
        <pubDate>Fri, 13 Jul 2018 02:25:36 -0500</pubDate>
        <link>
        /Building-Parallel-Corpora-Using-Cross-Lingual-Bag-Of-Words</link>
        <guid isPermaLink="true">/Building-Parallel-Corpora-Using-Cross-Lingual-Bag-Of-Words</guid>
      </item>
      
    
      
      <item>
        <title>Clause Augmentation for Better NMT</title>
        
          <description>&lt;p&gt;Most public parallel corpora are formed of long sentences. Consequently, neural translation models tend to generate a long output with n-grams repetition, even when they are exposed to a short sequence or a one-word example. This causes the repetition problem, explained by the fact that none of the neurons learns the representation of length, thus the model generates a long sequence by default. In other terms, the probability of appearance of the end-of-sentence token &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; will not be high enough to stop the output generation when translating a short sequences.&lt;/p&gt;

</description>
        
        <pubDate>Sun, 01 Apr 2018 02:25:36 -0500</pubDate>
        <link>
        /Clause-Augmentation-for-Better-NMT</link>
        <guid isPermaLink="true">/Clause-Augmentation-for-Better-NMT</guid>
      </item>
      
    
  </channel>
</rss>
