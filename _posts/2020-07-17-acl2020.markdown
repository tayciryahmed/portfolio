---
layout: post
current: post
cover: assets/images/seattle.jpg
navigation: True
title: ACL 2020 Highlights: Evaluation, Interpretability and more.
date: 2020-07-17 21:03:36
tags:
class: post-template
subclass: 'post'
author: tayciryahmed
---


This post discusses highlights of the main conference of the 2020 Annual Meeting of the Association for Computational Linguistics (ACL 2020). The conference accepted 779 papers with an acceptance rate of 22.7%, had 25 tracks along with demo sessions, virtual meetups and mentoring sessions. 

For the first time ever, this year's ACL conference has a special theme with a dedicated session and award: **Taking Stock of Where We've Been and Where We're Going**. The theme surely highlights the current state of the field. Indeed, the NLP research community has been pushing boundries in terms of performance ([GLUE](https://gluebenchmark.com/leaderboard/) benchmark), innovative architectures (transformer, BERT & co), quick access to SOTA (HuggingFace's [transformers](https://github.com/huggingface/transformers)) and model sizes ([GPT-3:](https://arxiv.org/abs/2005.14165) 175B parameters). As put by [Clement Delangue](https://twitter.com/ClementDelangue/status/1283411618395815936), Co-Founder and CEO of HuggingFace: "NLP is going to be the most transformational tech of the decade!" But at this growth pace, ACL Program Co-Chairs deemed healthy for the research community to take a step back and reflect on the current state of the field, to avoid getting stuck in suboptimal solutions and consciously chart out the roadmap for future research directions. 

In addition to the insightful theme choice, the Co-Chairs introduced 4 additional tracks including: [**Ethics and NLP** & **Interpretability and Analysis of Models for NLP**](https://acl2020.org/blog/the-first-call-for-papers-is-out/). Indeed, after many sessions and workshops in the previous \*CL events, the community is making it clear that responsible and ethical models are crucial as more NLP models are deployed in production and driving decisions that impact people's lives. Moreover, as research works continue to push performance boudries, interpreting and analysing models have become more relevant in order to understand the models inner mechanisms and learn about the secret ingredient that make these models as performant. 

We can see in the graph below that the most popular tracks in ACL 2020 are (1) Interpretability and Analysis of Models for NLP, (2) Theme, (3) Cognitive Modeling and Psycholinguistics and (4) Ethics and NLP.

![Views box-plot by area, sorted by median (by Yoav Goldberg)]({{site.baseurl}}assets/images/acl2020graph.png)

*Note that for [readability](https://twitter.com/yoavgo/status/1282459579339681792), 3 outliers were removed with 416 (Linzen et al), 533 (Gururangan et al) and 970 (Bender and Koller) views.*

Below are the topics on which I focused this year, which were also topics of interest for many other participants (c.f. links below): 

* Theme and Robust Evaluation
* Analysis, Interpretability and Ethics

## Theme and Robust Evaluation 

The theme *Taking Stock of Where We've Been and Where We're Going* illustrates the desire of the NLP community to make sure the current trend of training Machine Learning models to solve NLP problems, does not lead to a locally optimal state of the field's progress. This takes us back to the 90s, when introducing statistical methods to computational linguistics raised discussions between protagonists from both sides claiming the advantages of each approach. But, this is still a very interesting approach, since taking this step back to reflect on what the community needs to tackle, should put it back on track to building more insightful and fair models. As a matter of fact, during the past year, we have seen a trend of training ever bigger transformers on ever bigger datasets to break benchmark leaderboards, in a metrics-obsessed approach to research. This trend comes with its costs, financial ([GPT-3](https://arxiv.org/abs/2005.14165) costs $12 million), but also environmental and ethical. Indeed, so few groups have access to as much computational power and resources, which narrows the research competition. It also raises the question if bigger-is-better a scientific approach. To [quote](https://twitter.com/fchollet/status/1122330598968705025) Fran√ßois Chollet: "Training ever bigger convnets and LSTMs on ever bigger datasets gets us closer to Strong AI -- in the same sense that building taller towers gets us closer to the moon". Though, it is agreed upon that these methods are the result of impressive engineering acheivements, e.g. [Turing-NLG](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/) is the result of developing [`DeepSpeed`](https://github.com/microsoft/DeepSpeed), a deep learning optimization library for distributed training. Moreover, they are promissing methodologies for zero, one and few shots scopes, that are useful for many NLP applications. Nonetheless, the community is clearly having an existential moment and doing introspection to bypass this metrics-driven paradigm, in the quest to achieve human NLP ability in machines. Indeed, several talks argue that focusing on metrics drives us away from real linguistic challenges in the distribution's tail and that models, though beat human performance with respect to metrics, are unable to handle trivial example for the human mind. For instance, [Bender and Koller](https://www.aclweb.org/anthology/2020.acl-main.463.pdf) show in their theme wining paper that ...



 
* best theme paper (emily bender) 
* keynote1 
* best paper
* other papers on evaluation / Theme 


## Analysis, Interpretability and Ethics

* right to explanation https://en.wikipedia.org/wiki/Right_to_explanation
* Tutorial + papers : done 
* other papers on Ethics 

## See also
* [Selection of papers from ACL-2020](https://docs.google.com/document/d/1rQYAjY-jNKoQh8Z9-4NjqLF1_nAD7amr4sYH62eGPbU/edit#heading=h.lrgn79ao0for) by Yacine Jernite (HuggingFace)
* [Interpretability and Analysis of Models for NLP @ ACL 2020](https://medium.com/@lawrence.carolin/interpretability-and-analysis-of-models-for-nlp-e6b977ac1dc6) by Carolin Lawrence
* [Highlights of ACL 2020](https://medium.com/analytics-vidhya/highlights-of-acl-2020-4ef9f27a4f0c) by Vered Shwartz (AI2 & University of Washington)
* [Ten emerging topics at ACL 2020](https://europe.naverlabs.com/blog/ten-emerging-topics-at-acl-2020/) by NAVER LABS
* [Knowledge Graphs in Natural Language Processing @ ACL 2020](https://towardsdatascience.com/knowledge-graphs-in-natural-language-processing-acl-2020-ebb1f0a6e0b1) by Michael Galkin
* [ACL 2020 Adventure](https://awk.ai/notes/2020/07/10/acl-2020-adventure.html) by Qingqing Cao
